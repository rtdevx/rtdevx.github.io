[{"content":"","date":null,"permalink":"https://rtdevx.github.io/posts/","section":"Posts","summary":"","title":"Posts"},{"content":" My name is Rob and I am an experienced IT professional. On this blog I share thoughts and learnings about technical topics, such as: DevOps, Agile, Cloud, Windows, Linux, Ansible, Terraform, PowerShell.\nI am also interested in tools and techniques that help me increasing my productivity, so you will also find writings on zettelkasten, learning techniques and on occasion other, less related subjects\u0026hellip;\nNo rights reserved. For educational and informational purposes only. üë®üèª‚Äçüíª ","date":null,"permalink":"https://rtdevx.github.io/","section":"Welcome my blog. üéâ","summary":"","title":"Welcome my blog. üéâ"},{"content":"Experienced IT professional accomplished in supporting and delivering secure, resilient, and PCI-compliant infrastructure solutions across international payment ecosystems. I specialize in building and automating high-stakes platforms for credit and debit card transaction processing and fraud detection systems (3D-Secure). Resilient platforms and infrastructures trusted by global banks and financial institutions.\nA strong advocate of DevOps and Agile methodologies, I bring end-to-end transparency and automation to infrastructure delivery. Skilled across Linux and Windows Server environments, I leverage tools like Ansible and PowerShell to streamline provisioning, hardening, and support of critical systems.\nMy toolkit includes:\n‚Ä¢ Infrastructure automation and application provisioning (Ansible, PowerShell)\n‚Ä¢ Multi-disciplined - Linux, Windows Server and DevOps tools and techniques\n‚Ä¢ Agile delivery and Jira project design and automation\n‚Ä¢ Git, GitHub, Bitbucket (version control)\n‚Ä¢ SharePoint and Confluence (collaboration and documentation)\n‚Ä¢ Deep experience administering Microsoft server technologies\nI am currently learning: DevOps, GitOps, Ansible, AWS, Terraform and Kubernetes.\nFeel free to take look at my homelab GitHub page for more details.\n","date":"18 August 2025","permalink":"https://rtdevx.github.io/about/","section":"Welcome my blog. üéâ","summary":"Learn more about me and why I am starting this blog.","title":"About me"},{"content":"","date":null,"permalink":"https://rtdevx.github.io/tags/aws/","section":"Tags","summary":"","title":"AWS"},{"content":"","date":null,"permalink":"https://rtdevx.github.io/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"https://rtdevx.github.io/tags/clf-c02/","section":"Tags","summary":"","title":"CLF-C02"},{"content":"This section is about multiple applications communicating with each other.\nSynchronous communication (application to application) Can be problematic if there are sudden spikes of traffic Asynchronous / Event-based communication (application to queue to application) It is called decoupling of applications SQS: queue model SNS: pub / sub model Kinesis: real-time data streaming model Those services can scale independently from our application SQS #SQS = Simple Queue Service. # What is Amazon SQS\nSQS - Standard Queue # Oldest AWS offering (over 10 years old) Fully managed, serverless service used to decouple applications Sales from 1 message per second to 10,000s per second Default messages retention: 4 days, maximum 14 days No limit to how many messages can be in the queue Messages are deleted after they\u0026rsquo;re read by consumers (applications) Low latency Consumers share the work to read messages and scale horizontally SQS - FIFO Queue #FIFO = First in First Out (ordering of messages in the queue) # Messages are processed in order by the consumer.\nAmazon Kinesis #Kinesis = real-time big data streaming. #Managed service to collect, process and analyze real-time streaming data at any scale.\nAmazon SNS #SNS = Simple Notification Service. #SNS is sending one message to multiple receivers.\nThe \u0026ldquo;event publishers\u0026rdquo; only sending message to one SNS topic As many \u0026ldquo;event publishers\u0026rdquo; as we want to listen to the SNS topic notifications Each subscriber to the topic will get all the messages Up to 12,500,000 subscriptions per topic, 100,000 topics limit Amazon MQ #SQS and SNS are \u0026ldquo;cloud-native\u0026rdquo; services. Traditional applications running from on-premises may use open protocols, such as:\nMQTT AMQP STOMP Openwire WSS When migrating to the cloud, instead of re-engineering the application to use SQS and SNS, Amazon MQ can be used instead.\nAmazon MQ is a managed message broker service for:\nRabbitMQ\nActive MQ\nAmazon MQ doesn\u0026rsquo;t scale as much as SQS / SNS\nAmazon MQ runs on servers, can run in Multi-AZ with failover\nAmazon MQ has both - queue feature (~SQS) and topic features (~SNS)\nSummary # SQS Queue service in AWS Multiple Producers, messages kept up to 14 days Multiple Consumers share the read and delete messages when done Used to decouple applications in AWS SNS Notification service in AWS Subscribers: Email Lambda SQS HTTP Mobile Others Multiple Subscribers, sending all messages to all of them No message retention Kinesis Real-time data streaming Amazon MQ Managed message broker for Active MQ and Rabbit MQ in the cloud (MQTT, AMQP protocols) Sources # Amazon SQS: https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"16 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/16-cloud-integrations/","section":"Posts","summary":"Cloud Integrations / decoupling. This section is about multiple applications communicating with each other. SNS, SQS, MQ\u0026hellip;.","title":"Cloud Integrations"},{"content":"","date":null,"permalink":"https://rtdevx.github.io/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"https://rtdevx.github.io/categories/training-courses/","section":"Categories","summary":"","title":"Training Courses"},{"content":"A Global Application is an application deployed in multiple geographies. On AWS this could be Regions and / or Edge Locations.\nDecreased Latency Disaster Recovery (DOS / DDOS) Attack protection (distributed global infrastructure is harder to attack) More: https://aws.amazon.com/about-aws/global-infrastructure/\nRoute53 CloudFront (Global CDN) S3 Transfer Acceleration AWS Global Accelerator AWS Global Infrastructure Overview - Regions, Availability Zones, Edge Locations and more\nRoute53 #Route53 is managed DNS.\nHow Route 53 routes traffic for your domain\nRoute53 Routing Policies # Simple Routing Policy - No health checks,, just DNS check Weighted Routing Policy - Specify what amount of traffic goes where (i.e. 70% = Server1, 20% = Server2, 10% = Server3. Simple form of Load Balancing) Latency Routing Policy - Based on latency - minimizing the latency between user and the server sending the traffic that is geographically (latency-based) closer to the user Failover Routing Policy - Disaster Recovery (DR) - based on Health Checks Geolocation Routing Policy - Routing based specifically on Geolocation IP-based Routing Policy - Route the traffic based on the IP address originates from More on Routing Policies: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html\nAWS Route 53 Course\nRegistering a domain ## Register a Domain Route 53 \u0026gt; Registered Domains \u0026gt; Register Domain \u0026gt; CHOOSEADOMAIN.COM # Hosted zones Route 53 \u0026gt; Hosted zones \u0026gt; select \u0026#34;CHOOSEADOMAIN.COM\u0026#34; \u0026gt; Update the DNS records with the right EC2 instances, select an adequate Routing Policy More about Registering and managing domains: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html\nMore about Route 53: https://docs.aws.amazon.com/route53/\nAmazon CloudFront # Content Delivery Network (CDN) Improves read performance, content cached at the edge Improves users experience Many Points of Presence globally (Edge Locations, Edge Caches) DDoS protection (because it\u0026rsquo;s distributed globally) Integrated with Shield and AWS WAF (Web Application Firewall) CloudFront - Origins # S3 Bucket For distributing files and caching them at the edge For uploading files to S3 through CloudFront Secured using Origin Access Control (OAC) VPC Origin For applications hosted in VPC private subnets Application Load Balancer / Network Load Balancer / EC2 Instances Custom Origin (HTTP) S3 website (must first enable the bucket as a static S3 website) Any public HTTP backend How CloudFront delivers content\nCloudFront vs S3 Cross Region Replication #CloudFront # Global Edge Network Files are cached for a TTL (day?) Use case: static content that must be available everywhere S3 Cross Region Replication # Must be setup for each region you want your replication to happen Files are updated in near real-time Read-only Use case: dynamic content that needs to be available at low-latency in few regions only S3 Transfer Acceleration #Increase transfer speed by transferring files to an AWS edge location which will forward the data to the S3 bucket in the target region.\nAWS Global Accelerator #AWS Global Accelerator is used to improve global application availability and performance using the AWS global network.\nLeverage the AWS internal network to optimize the route to your application (60% improvement).\nMore about AWS Global Accelerator:\nhttps://aws.amazon.com/global-accelerator/ https://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.html https://speedtest.globalaccelerator.aws AWS Global Accelerator vs CloudFront # They both use AWS global network and it\u0026rsquo;s edge locations Both services integrate with AWS Shield for DDoS protection CloudFront - Content Delivery Network Improves performance for cacheable content (images, videos, etc.) Content is served at the edge Global Accelerator No caching, proxying packets at the edge to applications running in one or more AWS regions Improves performance for a wide range of applications running in one or more AWS regions Improves performance for a wide range of applications over TCP or UDP Good for HTTP use cases that require static IP addresses Good for HTTP use cases that require deterministic, fast, regional failover AWS Outposts #AWS Outposts = Hybrid Cloud appliances. #Outposts are \u0026ldquo;server racks\u0026rdquo; that offer the same AWS infrastructure, services, API\u0026rsquo;s \u0026amp; tools to build your own applications on-premises just as in the cloud.\nAWS will setup and manage Outposts racks within your on-premises infrastructure. #Benefits\nLow latency access to on-premises system Local data processing Data residency Easier migration from on-premises to the cloud Fully managed service Some example services that work on Outposts: EC2 EBS S3 EKS ECS RDS EMR Wavelength #Wavelength Zones are infrastructure deployments embedded within the telecommunication providers datacenters at the edge of the 5G networks.\nUltra low latency applications through 5G networks Traffic doesn\u0026rsquo;t leave the Communication Service Provider\u0026rsquo;s (CSP) network High bandwidth and secure connection to the parent AWS Region No additional charges or service agreements Use cases: Smart Cities ML-assisted (Machine Learning) diagnostics Connected Vehicles Interactive Live Video Streams AR / VR Real-time gaming AWS Local Zones #AWS Local Zones allow placing compute, storage, database and other selected AWS services closer to the users to run latency-sensitive applications.\nIt is an \u0026ldquo;Extension of AWS Region\u0026rdquo;.\nExample: # AWS Region: N. Virginia (us-east-1) AWS Local Zones: Boston, Chicago, Dallas, Houston, Miami, \u0026hellip; How AWS Local Zones work\nCompatible with: # EC2 RDS ECS EBS ElastiCache Direct Connect More\u0026hellip; More about AWS Local Zones: https://docs.aws.amazon.com/local-zones/latest/ug/what-is-aws-local-zones.html\nSummary #Route 53 - Global DNS # Great to route users to the closest deployment with least latency Great for Disaster Recovery - DR - Strategies CloudFront - Global CDN - Content Delivery Network # Replicate part of your application to AWS Edge Locations - decreased latency Cache common requests - improved user experience and decreased latency S3 Transfer Acceleration # Accelerate global uploads \u0026amp; downloads into Amazon S3 AWS Global Accelerator # Improve global application availability and performance using the AWS global network AWS Outposts # Deploy Outposts racks in an on-premises datacenter to extend some AWS services and for easier migration AWS Wavelength # Brings AWS services to the edge of the 5G networks Ultra-low latency applications AWS Local Zones # Bring AWS resources (compute, database, storage, \u0026hellip;) closer to your users Good for latency-sensitive applications Sources #Global Infrastructure: https://aws.amazon.com/about-aws/global-infrastructure/\nRoute 53 #Route 53: https://docs.aws.amazon.com/route53/ Route 53 Routing Policies: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html Registering and managing domains: https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar.html\nCloudFront #CloudFront: https://docs.aws.amazon.com/cloudfront/\nAWS Global Accelerator #https://aws.amazon.com/global-accelerator/ https://docs.aws.amazon.com/global-accelerator/latest/dg/what-is-global-accelerator.html https://speedtest.globalaccelerator.aws\nAWS Local Zones #https://docs.aws.amazon.com/local-zones/latest/ug/what-is-aws-local-zones.html\nReferences # S3 Security and Compliance Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"15 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/15-aws-global-infrastructure/","section":"Posts","summary":"A Global Application is an application deployed in multiple geographies. On AWS this could be Regions and / or Edge Locations\u0026hellip;.","title":"AWS Global Infrastructure"},{"content":"Deploying and Managing Infrastructure at scale #CloudFormation #CloudFormation is a declarative way of outlining an AWS infrastructure.\nExample:\nSecurity Group Two EC2 instances using this Security Group S3 Bucket Load Balancer (ELB) in front Then CloudFormation creates those resources in the right order and with the exact configuration that was specified (declared).\nIntroduction to AWS CloudFormation\nBenefits of CloudFormation # Infrastructure as Code No resources are manually created Changes to the infrastructure are reviewed through code Cost Each resource within the stack is tagged with an identifier so you can easily see how much a stack costs Cost can be estimated by using CloudFormation template Cost savings strategy: in Dev, automation can delete resources at 5pm and recreate at 8am automatically Productivity Ability to destroy and re-create and infrastructure in the cloud on the fly Declarative programming (no need to figure out ordering and orchestration) Don\u0026rsquo;t re-invent the wheel Leverage existing templates on the web Leverage the documentation Supports (almost) all AWS resources \u0026ldquo;Custom resources\u0026rdquo; can be used for resources that are not supported CloudFormation + Infrastructure Composer #Example: Wordpress CloudFormation Stack\nWe can see all the resources We can see the relations between components More: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/infrastructure-composer-for-cloudformation.html\nAWS Cloud Development Kit (CDK) # Define your cloud infrastructure using a familiar language: JavaScript/TypeScript, Python, Java, .NET For that reason infrastructure and application can be deployed \u0026ldquo;together\u0026rdquo; - they share the runtime The infrastructure code is converted into a CloudFormation template (JSON / YAML) Beanstalk #Elastic Beanstalk is a developer-centric view of deploying an application on AWS.\nIt uses all the components mentioned earlier (EC2, ASG, ELB, RDS, etc\u0026hellip;)\nBeanstalk = Platform as a Service (PaaS) # Managed service Instance configuration / OS is handled by Beanstalk Deployment strategy is configurable but performed by Elastic Beanstalk Capacity provisioning Load Balancing and Auto-Scaling Application health-monitoring and responsiveness Just the application code is the responsibility of the developer Three architecture models: Single instance deployment: for DEV environments LB + ASG: for prod or pre-prod web apps ASG only: for non-web apps in production (workers, etc\u0026hellip;) Beanstalk supports many platforms: # Go Java SE Java with Tomcat .NET on Windows Server with IIS Node.js PHP Python Ruby Packer Builder Single-Container Docker Multi-Container Docker Preconfigured Docker Beanstalk Health Agent pushes metrics to CloudWatch, checks for app health and publishes health events.\nAWS CodeDeploy #AWS CodeDeploy is a deployment service that automates application deployments to:\nEC2 instances as well as on-premise instances - it is a Hybrid service serverless Lambda functions Amazon ECS (Elastic Container Services) Servers / Instances must be provisioned and configured ahead of time with the CodeDeploy Agent.\nAWS CodeBuild #Code building service in the cloud.\nCodeBuild compiles source code, run tests, produces packages that are ready to be deployed.\nAWS CodePipeline #CodePipeline orchestrates the different steps to have the code automatically pushed to production.\nCode \u0026gt; Build \u0026gt; Test \u0026gt; Provision \u0026gt; Deploy AWS CodeArtifact #Software packages depends on each other to be built (also called code dependencies). Storing and retrieving those dependencies is called artifact management. Traditionally you need to setup your own artifact management system.\nCodeArtifact works with common dependency management tools such as:\nMaven, Gradle, npm, yarn, twine, pip, NuGet.\nDevelopers and CodeBuild can retrieve dependencies straight from CodeArtifact.\nSystems Manager (SSM) #SSM helps managing EC2 and On-Premises systems at scale.\nAnother Hybrid AWS service Get operational insights about the state of the infrastructure Suite of 10+ products Features: Patching automation for enhanced compliance Run commands across entire fleet of servers Store parameter configuration with the SSM Parameter Store Works with Linux, Windows, MacOS and Raspberry Pi OS (Raspbian) Allows starting SSH session on EC2 and On-Premise servers No SSH access, bastion hosts or SSH keys needed No port 22 needed Send session log data to S3 or CloudWatch Systems Manager Parameter Store # Secure storage for configuration and secrets API Keys, passwords, configurations Serverless, scalable, durable, easy SDK Control access permissions with IAM policies Version tracking and encryption (optional) More: https://docs.aws.amazon.com/systems-manager/\nSources # Infrastructure Composer: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/infrastructure-composer-for-cloudformation.html AWS Systems Manager (SSM): https://docs.aws.amazon.com/systems-manager/ Highlights # Infrastructure Composer Systems Manager (SSM) Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"14 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/14-deployments/","section":"Posts","summary":"Deploying and Managing Infrastructure at scale in AWS\u0026hellip;","title":"Deployments"},{"content":"Docker #Docker is a software development platform to deploy apps.\nApps are packaged in containers that can be run on any OS.\nApplications function in the same way, no matter where they\u0026rsquo;re run Any machine No compatibility issues Predictable behavior Less work Easier to maintain and deploy Scale containers up and down quickly (seconds) Docker images are stored in Docker Repositories.\nPublic: Docker Hub (https://hubl.docker.com) Private: Amazon ECR (Elastic Container Registry) ECS (Elastic Container Service) #Amazon ECS = Elastic Container Service. #ECS allows launching Docker containers on AWS. It is an orchestrator.\nYou must provision and maintain the infrastructure (EC2 instances) AWS takes care of starting / stopping containers Has integrations with the Application Load Balancer Fargate # Launch Docker containers on AWS Serverless. No need to provision the infrastructure (no EC2 instances to manage) AWS runs the containers based on CPU / RAM needed ECR # Elastic Container Registry Private Docker Registry on AWS Amazon EKS #Amazon EKS = Elastic Kubernetes Service.\nAllows launching and managing Kubernetes clusters on AWS.\nKubernetes is an open-source system for management, deployment and scaling of containerized apps (Docker, Containerd).\nContainers can be hosted on:\nEC2 instances Fargate Lambda # Virtual functions - no servers to manage Limited by time - short executions Run on-demand Scaling is automated Benefits of Lambda # Easy pricing: Pay per request and compute time Integrated with the whole AWS suite of services Event-Driven: functions get invoked by AWS when needed Integrated with many programming languages Node.js (JavaScript) Python Java C# (.NET Core) / PowerShell Ruby Custom Runtime API (community supported, example Rust or Golang) Easy monitoring through AWS CloudWatch Easy to get more resources per functions (up to 10 GB of RAM) Increasing RAM will also improve CPU and Network Lambda Container Image - although ECS / Fargate is preferred for running Docker images.\nLambda pricing is based on calls and duration.\nAmazon API Gateway # Fully managed service for developers to easily create, publish, maintain, monitor and secure APIs Serverless and scalable Supports RESTful APIs and WebSocket APIs Support for security, user authentication, API throttling, API keys, monitoring Creating Serverless API = API Gateway + Lambda. Expose Lambda functions as HTTP API. #AWS Batch # Fully managed batch processing at any scale Efficiently run 100,000s of computing batch jobs on AWS A \u0026ldquo;batch\u0026rdquo; job is a job with start and and end (opposed to continuous) Batch will dynamically launch EC2 instances or Spot instances AWS batch provisions the right amount of compute / memory You submit or schedule batch jobs and AWS Batch does the rest Batch jobs are defined as Docker images and run on ECS Helpful for cost optimizations and focusing less on the infrastructure Batch vs Lambda # Lambda Time limit Limited runtimes Limited temporary disk space Serverless Batch No time limit Any runtime as long as it\u0026rsquo;s packaged as a Docker image (no programming language dependency) Rely on EBS / instance store for disk space Relies on EC2 (can be managed by AWS) Lightsail # Virtual servers, storage, databases and networking Low \u0026amp; predictable pricing Simpler alternative to using EC2, RDS, ELB, EBS, Route53 Great for people with little cloud experience Can setup notifications and monitoring of your Lightsail resources Use cases: Simple web applications Websites Dev / Test environment Has High Availability but no auto scaling, limited AWS integrations Summary # Docker: container technology to run applications ECS: run Docker container on EC2 instances Fargate: Run Docker containers without provisioning the infrastructure Serverless offering (no EC2 instances) ECR: Private Docker Images Repository Batch: run batch jobs on AWS across managed EC2 instances Lightsail: predictable \u0026amp; low pricing for simple application \u0026amp; DB stacks Lambda: Serverless, Function as a Service, seamless scaling, reactive Lambda Billing: By the time run x by the RAM provisioned By the number of invocations Language support: many programming languages except (arbitrary) Docker Invocation time: up to 15 minutes API Gateway: expose Lambda functions as HTTP API Sources # ECS Documentation: https://docs.aws.amazon.com/ecs/ References # EC2 Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"13 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/13-other-compute-services/","section":"Posts","summary":"Other Compute Services in AWS cloud\u0026hellip;","title":"Other Compute Services"},{"content":"Relational Databases #A relational database is a type of database that organizes data into rows and columns, which collectively form a table where the data points are related to each other.\nData is typically structured across multiple tables, which can be joined together via a primary key or a foreign key. These unique identifiers demonstrate the different relationships which exist between tables, and these relationships are usually illustrated through different types of data models.\nNo-SQL Databases # No-SQL = non-relational databases No-SQL databases are purpose built for specific data models and have flexible schemas for building modern applications Benefits:\nFlexibility (easy to evolve data model) Scalability (designed to scale out by using distributed clusters) High-Performance (optimized for a specific data model) Highly functional (types optimized for the data model) Use cases: Key-value, document, graph, in-memory, search datamases\nRDS and Aurora #Amazon RDS #RDS stands for Relational Database Service. It is a managed DB service.\nIt allows creating databases in the cloud that are managed by AWS:\nPostgres MySQL MariaDB Oracle Microsoft SQL Server IBM DB2 Aurora (AWS Proprietary) Advantage of using RDS vs deploying DB on EC2:\nRDS is a managed service Automated Provisioning and OS patching Continuous backups and restore to specific timestamp (Point in Time Restore) Monitoring dashboards Read replicas for improved read performance Multi-AZ setup for DR Maintenance windows for upgrades Scaling capability (both, vertical and horizontal) Storage backed by EBS Not possible to SSH into DB instances (managed service) Example RDS application architecture # Source: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html\nAmazon Aurora # Aurora is proprietary technology from AWS (not open sourced) PostgreSQL and MySQL are both supported Aurora is \u0026ldquo;AWS Optimized\u0026rdquo; and claims to be 5x performance improved over MySQL on RDS and 3x the performance of Postgres on RDS Aurora storage automatically grows and increments of 10GB (up to 128 TB) Aurora costs about 20% more than RDS Amazon Aurora Serverless # Automated (on-demand) database with autoscaling based on actual usage PostgreSQL and MySQL are both supported as Aurora Serverless DB No capacity planning required Least management overhead Pay-per-second, COULD BE more effective Use cases: infrequent, intermittent or unpredictable workloads.\nAurora with no management overhead = Aurora Serverless. #Create RDS database #Aurora and RDS \u0026gt; Create a database RDS Deployment options # Read Replicas Scale the read workload of your DB Can create up to 15 replicas Data is only written to the main DB Multi-AZ Failover in case of AZ outage (High Availability) Data only read/written to the main DB Can only have 1 AZ as a failover Multi-Region Multi-Region (Read Replicas) Writes only to the main database Local performance for global reads Additional replication cost Use case: DR in another region Other Database Types #Amazon ElastiCache # The same way RDS is to get managed Relational Databases, ElastiCache is to get managed Redis or Memcached.\nCaches are in-memory databases with high performance and low latency\nHelps reducing load from databases with read-intensive workloads\nAWS taking care of OS maintenance, patching, optimizations, setup, configuration, monitoring, failure recovery and backups\nMore: https://docs.aws.amazon.com/elasticache/\nDynamoDB # Fully managed, Highly Available with replication across 3AZ No-SQL database - not a relational DB Scales to massive workloads, distributed, \u0026ldquo;serverless\u0026rdquo; Millions of requests per second, trillions of row, 100s TB of storage Fast and consistent performance Single-digit millisecond latency Integrated with IAM for security, authorization and administration Low cost and auto scaling capabilities Standard \u0026amp; Infrequent Access (IA) Table Class DynamoDB Accelerator (DAX) # Fully Managed in-memory cache for DynamoDB 10x performance improvement when accessing DynamoDB tables DAX is only used for DynamoDB where Elasticache can be used for other databases.\nDynamoDB Global Tables # Makes DynamoDB table accessible with low latency in multiple-regions Active-Active replication (read/write to any AWS Region) Redshift # Redshift is based on PostgreSQL It\u0026rsquo;s OLAP - Online Analytical Processing (analytics and data warehousing) Load data once every hour, not every second 10x better performance than other data warehouses Scales to PBs of data Columnar storage of data (instead of rows) Massively Parallel Query Execution (MPP) Pay-as-you-go based on the instances provisioned Has a SQL interface for performing queries Redshift Serverless # Auto Scaling Run analytics workload without managing data warehouse infrastructure Pay only for what you use Use cases: Reporting, real-time analytics Amazon EMR # EMR stands for \u0026ldquo;Elastic MapReduce\u0026rdquo; EMR helps creating Hadoop clusters (Big Data) to analyze and process vast amounts of data The clusters can be made of hundreds of EC2 instances EMR takes care of all the provisioning and configuration Auto-scaling and integrated with Spot instances Use cases: data processing, machine learning, web indexing, big data Athena # Serverless query service to perform analytics against S3 objects Uses standard SQL language to query the files Supports CSV, JSON, ORD, Avro, Parquet Pricing: $5 per TB of data scanned Use cases: Business intelligence, analytics, reporting, analyze \u0026amp; query VPC Flow Logs, ELB Logs, CloudTrail logs, etc. Exam tip: analyze data in S3 using serverless SQL = Athena #QuickSight #Allows creating dashboards for services used in AWS. Per-session pricing.\nServerless machine-learning powered business intelligence service to create interactive dashboards Use cases: Business analytics Building visualisations Ad-hoc analysis Get business insights using data Integrated with RDS, Aurora, Athena, Redshift, S3 More: https://docs.aws.amazon.com/quicksight/\nDocumentDB #Aurora version for MongoDB (NoSQL database).\nMongoDB is used to store, query and index JSON data Fully Managed, Highly Available with replication across 3AZ DocumentDB storage automatically grows in increments of 10 GB Neptune # Fully managed graph database A popular graph dataset would be a social network Users have friends Posts have comments Comments have likes from users Users share and like posts Highly Available across 3AZ with up to 15 replicas Build and run applications working with highly connected datasets = optimized for those complex queries Can store up to billions of relations and query the graph with milliseconds latency Use cases: knowledge graphs (Wikipedia), fraud detection, recommendation engines, social networking Amazon Timestream # Serverless time series database Automatically scales up and down to adjust capacity Store and analyze trillions of events per day Amazon managed Blockchain # Blockchain makes it possible to build applications where multiple parties can execute transactions without the need for a trusted, central authority Amazon managed Blockchain is a managed service that allows: Join public Blockchain networks Create your own scalable, private network Compatible with: Hyperledger Fabric Ethereum AWS Glue #Managed Extract, Transform and Load (ETL) service.\nUseful to prepare and transform data for analytics Fully serverless service DMS #DMS - Database Migration Service\nQuick and secure migrate databases to AWS\nThe source database remains available during the migration\nHomogeneous migrations: i.e. Oracle to Oracle\nHeterogeneous migrations: i.e. MSSQL to Aurora\nDatabase Summary # Relational Databases - OLTP: RDS \u0026amp; Aurora (SQL) Differences between Multi-AZ, Read Replicas, Multi-Region In-memory Database: ElastiCache Key/Value Database: DynamoDB (serverless) \u0026amp; DAX (cache for DynamoDB) Warehouse - OLAP: Redshift (SQL) Hadoop Cluster: EMR Athena: query data on Amazon S3 (serverless \u0026amp; SQL) QuickSight: dashboards on your data (serverless) DocumentDB: ‚ÄúAurora for MongoDB‚Äù (JSON ‚Äì NoSQL database) Amazon QLDB: Financial Transactions Ledger (immutable journal, cryptographically verifiable) Amazon Managed Blockchain: managed Hyperledger Fabric \u0026amp; Ethereum blockchains Glue: Managed ETL (Extract Transform Load) and Data Catalog service Database Migration: DMS Neptune: graph database Timestream: time-series database Sources # Amazon RDS and Aurora Documentation: https://docs.aws.amazon.com/rds/ ElastiCache: https://docs.aws.amazon.com/elasticache/ QuickSight: https://docs.aws.amazon.com/quicksight/ Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"12 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/12-databases/","section":"Posts","summary":"AWS oÔ¨Äers a growing number of database options (15+) with diverse data models to support a variety of workloads. These include relational, key-value, document, in-memory, graph, time series, vector, and wide-column\u0026hellip;","title":"Databases"},{"content":"What is Amazon S3 #Amazon S3 is one of the main building blocks of AWS.\nIt is advertised as \u0026ldquo;infinitely scaling\u0026rdquo; storage.\nMany websites use Amazon S3 as a backbone Many AWS services use Amazon S3 as an integration AWS S3 Full Course | From Beginner to Expert | Deploy Real-Time Projects on AWS\nAmazon S3 Use Cases # Backup and Storage Disaster Recovery Archive Hybrid Cloud storage Application hosting Media hosting Data lakes \u0026amp; big data analytics Software delivery Static Website Amazon S3 - Buckets # Amazon S3 allows people to store objects (files) in \u0026ldquo;buckets\u0026rdquo; (folders) Buckets must have a globally unique name (across all regions and all accounts) Buckets are defined at the region level S3 looks like a global service but buckets are created in a region S3 Bucket naming convention # No uppercase No underscore 3-63 characters long Not an IP Must start with lowercase letter or number Must NOT start with the prefix \u0026ldquo;xn\u0026ndash;\u0026rdquo; Must NOT start with the suffix \u0026ldquo;s3alias\u0026rdquo; Amazon S3 - Objects # Objects (files) have a Key\nThe key is the FULL path:\ns3://my-bucket/my_file.txt s3://my-bucket/my_folder/another_folder/my_file.txt The key is composed of prefix + object name\ns3://my-bucket/my_folder/another_folder/my_file.txt There is no concept of \u0026ldquo;directories\u0026rdquo; within S3 buckets (although UI will suggest there is)\nJust keys with very long names that contain slashes (\u0026quot;/\u0026quot;) Object values are the content of the body\nMax Object size is 5TB If uploading more than 5GB, must be \u0026ldquo;multi-part upload\u0026rdquo; Metadata (list of text key / value pairs - system or user metadata) Tags (Unicode key / value pair - up to 10) - used for security / lifecycle Amazon S3 - Security # User-based IAM Policies - which API calls should be allowed for a specific user from IAM Resource-based Bucket policies - bucket-wide rules from the S3 console - allows cross account Object Access Control List (ACL) - finer grain (can be disabled) Bucket Access Control List (ACL) - less common (can be disabled) IAM Principal can access an S3 object if The user IAM permissions ALLOW it OR the resource policy ALLOWS it AND there is no explicit DENY Encryption - encrypt objects in Amazon S3 using encryption keys S3 Bucket Policies # JSON based policies\nResources: buckets and objects Effect: Allow / Deny Actions: Set of API to Allow or Deny Principal: The account or user to apply the policy to Use S3 bucket policy to:\nGrant public access to the bucket Force objects to be encrypted at upload Grant access to another account (Cross Account) Examples # Public access - Bucket Policy User access to S3 - IAM permissions EC2 instance access - IAM Roles Cross-Account access - Bucket Policy Bucket settings for Block Public Access\nThose settings were created to prevent company data leaks If you know your bucket should never be public, leave them Applying Bucket Policy #S3 \u0026gt; General purpose buckets (or other) \u0026gt; your-bucket \u0026gt; Permissions \u0026gt; Ensure Allow public access is enabled Edit Bucket policy (follow Policy examples OR Policy Generator)\nPolicy Generator # \u0026ldquo;arn\u0026rdquo; can be found in the bucket settings itself \u0026ldquo;/*\u0026rdquo; can / should be added to propagate to all objects in the bucket Add Statement and copy the generated policy to Bucket policy\nObject(s) in that bucket should now be available from the internet via URL\nS3 - Static Website Hosting #Bucket must be made public (S3 Bucket policy, see above) in order for the static website to work. If it isn\u0026rsquo;t then 403 Forbidden error appears.\nEnable static website hosting #S3 \u0026gt; General purpose buckets (or other) \u0026gt; your-bucket \u0026gt; Properties \u0026gt; Static website hosting Voila! # Although no HTTPS enabled! - check \u0026ldquo;AWS Certificate Manager (ACM)\u0026rdquo; section in Security and Compliance on how to use ACM for SSL / TLS certificate management.\nAmazon S3 - Versioning # Versioning can be enabled at the bucket level Versioning buckets: Protect against unintended deletes (ability to restore the version) Easy roll back to previous version Notes: Any file that is not versioned prior to enabling versioning will have version \u0026ldquo;null\u0026rdquo; Suspending versioning does not delete the previous versions Enable S3 Versioning #S3 \u0026gt; General purpose buckets (or other) \u0026gt; your-bucket \u0026gt; Properties \u0026gt; Bucket Versioning \u0026gt; Edit \u0026gt; Enable In order to restore the file, toggle \u0026ldquo;Show Versions\u0026rdquo; switch and DELETE unwanted object (destructive, will permanently delete).\nIf \u0026ldquo;show versions\u0026rdquo; toggle is off, object can be safely deleted. It will NOT be permanently deleted, only \u0026ldquo;Delete marker\u0026rdquo; will be applied. Object can be easily restored when \u0026ldquo;Show versions\u0026rdquo; is ON. #S3 - Replication # CRR - Cross Region Replication SRR - Same Region Replication For S3 replication to work, Versioning must be enabled on both - source and destination buckets. Buckets can be different AWS Accounts.\nCopying is asynchronous, proper IAM permissions must be applied to S3.\nUse Cases: # CRR - compliance, lower latency access, replication across accounts SRR - log aggregation, live replication between production and test accounts Enabling S3 Replication # Create 2 new buckets and enable Versioning in both\nrk-test-replica-london-origin rk-test-replica-irl-dest On the origin bucket create the Replication rules\nEnable replication Select source and destination buckets Create IAM role or select an existing one (Create) Select any other options (encryption, destination storage class, delete marker replication and so on) S3 Storage Classes #Standard # Amazon S3 Standard - General Purpose 99.99% Availability Used for frequently accessed data Low latency and high throughput Sustain 2 concurrent facility failures Use cases: Big Data analytics, mobile \u0026amp; gaming applications, content distribution Infrequent access #For data that is less frequently accessed but requires rapid access when needed. Lower cost than S3 Standard.\nAmazon S3 Standard-Infrequent Access (IA) 99.9% Availability Use cases: Disaster Recovery, backups Amazon S3 One Zone-Infrequent Access For data that is less frequently accessed but requires rapid access when needed High Durability (99.999999999% Availability in a single AZ) 99.5% Availability Use cases: Secondary backup copies of on-prem data, data can be recreated Glacier #Low-cost object storage for archiving / backup.\nPricing includes storage price + retrieval cost.\nAmazon S3 Glacier Instant Retrieval Milliseconds retrieval, great for data accessed once a quarter Minimum storage duration of 90 days Amazon S3 Glacier Flexible Retrieval Expedited (1 to 5 mins), Standard (3 to 5 hours), Bulk (5 to 12 hours) - free Amazon S3 Glacier Deep Archive For long-term storage Standard (12 hours), Bulk (48 hours) Minimum storage duration of 180 days Intelligent tiering #Moves objects automatically between Storage Tiers based on usage for a small monthly monitoring and auto-tiering fee.\nThere is no retrieval charges in S3 Intelligent Tiering.\nFrequent Access tier (automatic): default tier Infrequent Access tier (automatic): objects not accessed for 30 days Archive instant Access tier (automatic): objects not accessed for 90 days Archive Access tier (optional): configurable from 90 to 700+ days Deep Archive Access tier (optional): configurable from 180 to 700+ days Objects can be moved between classes manually or using S3 Lifecycle policies.\nMore:\nS3 Storage classes: https://aws.amazon.com/s3/storage-classes/ S3 Pricing: https://aws.amazon.com/s3/pricing/ S3 Durability and Availability # Durability High durability (99.999999999, 11 9\u0026rsquo;s) of objects across multiple AZ If you store 10,000,000 objects with Amazon S3, you can on average expect to incur a loss of a single object once every 10,000 years Same for all storage classes Availability Measures how readily available a service is Varies depending on storage class Example: S3 standard has 99.99% availability = not available for 53 minutes a year More:\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/DataDurability.html https://aws.amazon.com/s3/storage-classes/ S3 Encryption # Server-Side Encryption (Default) Client-Side Encryption (Encrypted by user at the client side) IAM Access Analyzer for S3 # Ensures that only intended people have access to your S3 buckets Example: publicly accessible bucket, bucket shared with other AWS account Evaluates S3 Bucket Policies, S3 ACLs, S3 Access Point Policies Powered by IAM Access Analyzer AWS Snowball # Highly-secure, portable devices to collect and process data at the edge and / or migrate data in and out of AWS Helps to migrate up to Petabytes of data It is recommended to use AWS Snowball devices if it would take more than a week to transfer over the network. # More:\nhttps://aws.amazon.com/snowball/ https://aws.amazon.com/snowball/pricing/ AWS Storage Gateway #Amazon S3 File Gateway connects on-premises applications to the cloud to store and access archive repositories, application data, database backups and so on.\nS3 File Gateway is used for on-premises data intensive applications that need file protocol access to objects in S3.\nMore: https://aws.amazon.com/storagegateway/file/s3/\nTypes of Storage Gateway: # File Gateway Volume Gateway Tape Gateway Sources # S3 Documentation: https://docs.aws.amazon.com/s3/ S3 Availability and Durability: https://docs.aws.amazon.com/AmazonS3/latest/userguide/DataDurability.html S3 Storage Classes: https://aws.amazon.com/s3/storage-classes/ S3 Pricing: https://aws.amazon.com/s3/pricing/ S3 AWS Snowball: https://aws.amazon.com/snowball/ S3 File Gateway: https://aws.amazon.com/storagegateway/file/s3/ Full YouTube Rahul\u0026rsquo;s AWS Course: https://www.youtube.com/playlist?list=PL7iMyoQPMtAN4xl6oWzafqJebfay7K8KP\nReferences # Storage Security and Compliance Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"11 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/11-s3/","section":"Posts","summary":"Amazon S3 is one of the main building blocks of AWS. It is advertised as \u0026ldquo;infinitely scaling\u0026rdquo; storage\u0026hellip;","title":"Amazon S3"},{"content":"Auto Scaling Group contains a collection of EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management.\nAuto Scaling Group uses Auto Scaling features such as health check replacements and scaling policies.\nAWS EC2 Auto Scaling : Step By Step Tutorial\nThe purpose of Auto Scaling Group # Scale out (add EC2 instances) to match an increased load Scale in (remove EC2 instances) to match a decreased load Ensure we have a minimum and maximum number of instances running Automatically register new instances to the Load Balancer Replace unhealthy instances Cost Saving (only run at optimal capacity) Creating an Auto Scaling Group # Create Launch Template Create Auto Scaling Group Select Availability Zones Select Availability Zone distribution Attach to an existing Load Balancer Turn on Elastic Load Balancing health checks Define the desired capacity Set up Automatic Scaling (optional) Select Instance maintenance policy Additional capacity settings Additional settings Auto Scaling Groups - Strategies # Manual Scaling - update the size of an ASG manually Dynamic Scaling - respond to changing demand Simple / Step Scaling When a CloudWatch alarm is triggered (i.e. CPU \u0026gt; 70%) then add 2 instances When a Cloud Watch alarm is triggered (i.e. CPU \u0026lt; 30%) then remove 1 instance Target Tracking Scaling Example: Average ASG CPU to stay around 40% Scheduled Scaling Anticipate a scaling based on known usage patterns Example: increase the min. capacity to 10 at 5pm on Fridays Predictive Scaling Uses Machine Learning to predict the load Sources # https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html Full YouTube Rahul\u0026rsquo;s AWS Course: https://www.youtube.com/playlist?list=PL7iMyoQPMtAN4xl6oWzafqJebfay7K8KP\nReferences # Scalability \u0026amp; High Availability Elastic Load Balancing Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"10 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/10-auto-scaling-groups/","section":"Posts","summary":"Auto Scaling Group contains a collection of EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management\u0026hellip;","title":"Auto Scaling Group"},{"content":"Elastic Load Balancing automatically distributes your incoming traffic across multiple targets (EC2 instances, containers, IP addresses) in one or more Availability Zones.\nIt monitors the health of its registered targets and routes the traffic only to healthy targets.\nAWS Elastic Load Balancing Introduction\nBenefits of using Load Balancer # Spread load across multiple downstream instances\nExpose a single point of access (DNS) to the application\nSeamlessly handle failures of downstream instances\nDo regular health checks to the instances\nSSL termination\nHigh Availability across Availability Zones\nELB is a managed Load Balancer\nAWS is responsible for upgrades, maintenance and High Availability AWS provides only a few configuration items 3 kinds of Load Balancers offered by AWS # Application Load Balancer Network Load Balancer Gateway Load Balancer HTTP / HTTPS / gRPC protocols (Layer 7) TCP / UDP protocols (Layer 4) Geneve Protocol on IP Packets (Layer 3) HTTP Routing features High Performance (millions or requests per second) Route Traffic to Firewalls that you manage on EC2 instances Static DNS (URL) Static IP through Elastic IP Intrusion Detection 1. Application Load Balancer # HTTP / HTTPS only (Layer 7) AWS ALB (Application Load Balancer) - Step By Step Tutorial\n2. Network Load Balancer # ultra high performance, allows for TCP (Layer 4) Mastering AWS Network Load Balancer | ALB vs NLB | Step by Step Tutorial\n3. Gateway Load Balancer # Supports GENEVE protocol. Built for extra security (Layer 3) Sources # https://aws.amazon.com/elasticloadbalancing/ https://aws.amazon.com/compare/the-difference-between-the-difference-between-application-network-and-gateway-load-balancing/ https://medium.com/@xiaotiancheng.orange/comparison-between-alb-nlb-and-glb-4444f3291173 https://tutorialsdojo.com/application-load-balancer-vs-network-load-balancer-vs-gateway-load-balancer/ Stephane Maarek\u0026rsquo;s AWS playlists on YouTube: https://www.youtube.com/@StephaneMaarek/playlists Full YouTube Rahul\u0026rsquo;s AWS Course: https://www.youtube.com/playlist?list=PL7iMyoQPMtAN4xl6oWzafqJebfay7K8KP\nReferences # Scalability \u0026amp; High Availability Auto Scaling Groups Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"9 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/9-elastic-load-balancing/","section":"Posts","summary":"Elastic Load Balancing automatically distributes your incoming traffic across multiple targets\u0026hellip;","title":"Elastic Load Balancing"},{"content":"Scalability #Scalability means that an application / infrastructure can handle greater loads by adapting.\nTwo kinds of scalability # Vertical Scalability Increasing the size of an instance Very common for non-distributed systems, i.e. Databases Hardware limits apply Horizontal Scalability (Elasticity) Increasing the number of instances Implies Distributed Systems Very common for web applications or modern applications Auto Scaling Groups For Horizontal Scaling (increasing the number of instances) we use Auto Scaling Group and a Load Balancer High Availability # High Availability usually goes hand in hand with horizontal scaling High Availability means running application / infrastructure in at least 2 Availability Zones Goal of High Availability is to survive a data center loss / disaster High Availability is achieved by running Auto Scaling Groups (ASG) as well as Load Balancer in multi-AZ mode. # References # Elastic Load Balancing Auto Scaling Groups Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"8 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/8-scalability-high-availability/","section":"Posts","summary":"Scalability means that an application / infrastructure can handle greater loads by adapting\u0026hellip;","title":"Scalability \u0026 High Availability"},{"content":"What is Amazon EC2 AMI #AMI are a customization of an EC2 instance.\nCustom software, configuration, etc. can be added Faster boot / configuration time because all your software is pre-packaged AWS EC2 AMI Tutorial\nAMI are build for a specific AWS region but can be copied across regions.\nAMI can be launched from # Public AMI - AWS provided Own AMI - managed by an organization AWS Marketplace - created by a vendor or another 3rd party (can be sold / bought) Steps to build an AMI # Start EC2 Instance and customize it Stop the instance (for data integrity) Build AMI - this will also create EBS snapshots Launch instances from other AMI\u0026rsquo;s EC2 \u0026gt; Instances \u0026gt; Select an EC2 instance \u0026gt; Actions \u0026gt; Image and Templates \u0026gt; Create image EC2 Image Builder #EC2 Image Builder is a fully managed AWS service that helps you to automate the creation, management and deployment of customized, secure and up-to-date server images.\nCustom images can be created via AWS Console, AWS CLI or API.\nAutomate the creation, maintain, validate the build of EC2 AMI\u0026rsquo;s. Can run on a schedule and can be distributed to multiple AWS Regions.\nSources # What is Image Builder Stephane Maarek\u0026rsquo;s AWS playlists on YouTube: https://www.youtube.com/@StephaneMaarek/playlists\nReferences # EC2 Storage Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"7 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/7-ami/","section":"Posts","summary":"AMI are a customization of an EC2 instance\u0026hellip;","title":"Amazon Machine Image (AMI)"},{"content":"EBS Volume # EBS (Elastic Block Store) - Network drive that can be attached to instances while they run It allows instances to persist the data, even after their termination Can be mounted to 1 instance at a time Bound to an Availability Zone It\u0026rsquo;s a \u0026ldquo;Network Drive\u0026rdquo; it uses the network to communicate to the instance (there can be latency) it can be detached from an EC2 instance and attached to another one quickly It\u0026rsquo;s locked to an Availability Zone (AZ) an EBS Volume that is us-east-1a can\u0026rsquo;t be attached to us-east-1b to move a volume across AZ, snapshot has to be created first It has a provisioned capacity (size in GB and IOPS) you will get billed for a provisioned capacity You can increase the capacity of the drive EBS Volumes can be attached to only 1 EC2 instance at a time but EC2 instances can have multiple EBS Volumes attached to them\nEBS Delete on Termination # Controls the EBS behavior when EC2 instance terminates by default the root EBS volume is deleted (attribute enabled) by default any other attached EBS volume is not deleted (attribute disabled) This can be controlled by both, AWS Console and AWS CLI Use case: preserve root volume when instance is terminated EBS Snapshots # Make a backup (snapshot) of EBS volume at a point in time Not necessary to detach the volume to do the snapshot but recommended Snapshots can be copied across AZ or Regions EBS Snapshots features # EBS Snapshot Archive Move a Snapshot to an \u0026ldquo;archive tier\u0026rdquo; that is 75% cheaper Takes between 24 to 72 hours of restoring the archive EC2 \u0026gt; Snapshots \u0026gt; Recycle Bin \u0026gt; Create retention rule When Snapshot Archive is enabled, it is possible to Archive it from a drop-down box in AWS Console. Archived Snapshot appears in the Recycle Bin\nRecycle Bin for EBS Snapshots Setup rules to retain deleted snapshots so you can recover them after an accidental deletion Specify retention (from 1 day to 1 year) EC2 Instance Store # EBS volumes are network drives with good but \u0026ldquo;limited\u0026rdquo; performance\nIf high-performance hardware disk is required, EC2 Instance Store can be used\nBetter I/O performance\nEC2 Instance Store is ephemeral (data is lost after stopping EC2 instance)\nUse case: buffer, cache, scratch data, temporary content\nRisk of data loss if hardware fails.\nEFS - Elastic File System # Managed NFS (Network File System) that can be mounted on 100s of EC2 instances EFS works with Linux EC2 instances only and is multi-AZ. Highly-available, scalable, expensive (3x gp2 EBS), pay per use, no capacity planning EFS Infrequent Access (EFS-IA) # Storage class that is cost-optimized for files not accessed every day up to 92% lower cost compared to EFS Standard When enabled, EFS will automatically move your files to EFS-IA based on last time they were accessed Enable EFS-IA with a Lifecycle Policy Example: move files that are not accessed for 60 days to EFS-IA Transparent to the applications accessing EFS (apps don\u0026rsquo;t see whether file is in EFS or EFS-IA) EBS vs EFS # Feature EBS EFS Access Model Single-instance Multi-instance Use Cases Databases, Development Web serving, big data Performance Low-latency, high IOPS High throughput Scalability Limited to provisioned volume Auto-scales to petabytes File Size Limit No limit 47.9 TiB Accessibility Not accessible over the internet Shared across instances Pricing Cheaper for single-instance Cost-effective for shared use More: https://aws.amazon.com/efs/when-to-choose-efs/ https://lucidity.cloud/blog/ebs-vs-efs https://www.cloudzero.com/blog/ebs-vs-efs/ Amazon FSx #3rd party with high-performance file system on AWS.\nFSx for Lustre - fully managed, high-performance, scalable file storage for High Performance Computing (HPC). Use cases: Machine Learning, Analytics, Video processing, Financial Modelling Scales up to 100s GB/s, millions of IOPS, sub-ms latencies FSx for Windows File Server - fully managed, highly reliable and scalable Windows native shared file system built on Windows File Server. Supports SMB and NTFS file systems. Integrated with AD for security. Can be accessed from AWS or from On-Premise. FSx for NetApp ONTAP - Summary #EBS Volumes # network drives attached to one EC2 instance at a time Mapped to an Availability Zones Can use EBS snapshots for backups and then transferring across AZ\u0026rsquo;s AMI # Create ready-to-use EC2 instances with own customizations EC2 Image Builder # automatically build, test and distribute AMI\u0026rsquo;s EC2 Instance Store # high performance hardware disk attached to our EC2 instance ephemeral (data lost if instance stopped or terminated) EFS # Network File System Can be attached to 100s of EC2 instances spans through a region expensive compared to EBS EFS-IA # Cost-optimized storage class for infrequently accessed files Lifecycle Policy for automatically moving files between tiers FSx for Windows # Network File System for Windows servers SMB and NTFS Can be accessed from on-prem and the cloud FSx for Lustre # High Performance (HPC) Linux file system Sources # https://aws.amazon.com/efs/when-to-choose-efs/ https://lucidity.cloud/blog/ebs-vs-efs https://www.cloudzero.com/blog/ebs-vs-efs/ References # S3 EC2 AMI Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"6 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/6-storage/","section":"Posts","summary":"Storage in AWS\u0026hellip;","title":"Storage"},{"content":"Amazon Security Groups # Security Groups are the fundamental of network security in AWS They control how traffic is allowed in or out of our EC2 instances Security Groups only contain allow rules Security Groups rules can reference an IP or another Security Group Security Groups are acting as a \u0026ldquo;firewall\u0026rdquo; for EC2 instances Security Groups scope # Access to Ports Authorized IP ranges - IPv4 and IPv6 Control inbound network Control outbound network Security Groups principals # Can be attached to multiple instances Locked down to a region / VPC combination Lives \u0026ldquo;outside\u0026rdquo; of an EC2 instance - if traffic is blocked, EC2 won\u0026rsquo;t see it It\u0026rsquo;s a good practice to maintain one separate SG for SSH access If application is not accessible (time out) then it\u0026rsquo;s a Security Group issue If application gives a \u0026ldquo;connection refused\u0026rdquo; error then it\u0026rsquo;s an application error or it\u0026rsquo;s not launched All inbound traffic is blocked by default All outbound traffic is allowed by default Sources # Full YouTube Rahul\u0026rsquo;s AWS Course: https://www.youtube.com/playlist?list=PL7iMyoQPMtAN4xl6oWzafqJebfay7K8KP\nDisclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"5 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/5-security-groups/","section":"Posts","summary":"AWS Security Groups are the fundamental of network security in AWS. They control how traffic is allowed in or out of our EC2 instances\u0026hellip;","title":"Security Groups"},{"content":"What is Amazon EC2 #An Amazon EC2 instance is a virtual server in the AWS Cloud. When you launch an EC2 instance, the instance type that you specify determines the hardware available to your instance. Each instance type offers a different balance of compute, memory, network, and storage resources.\nEC2 sizing and configuration options # Operating System (OS) - Linux, Windows, Mac OS How much compute power \u0026amp; CPU cores How much RAM How much storage space Network-attached (EBS \u0026amp; EFS) Hardware (EC2 Instance Store) Network card: speed of the card, Public IP address Firewall rules: security group Bootstrap script (configure at first launch): EC2 User Data Amazon EC2 Instance Types #More info: EC2 Instance Types EC2Instances.info\nGeneral Purpose (M, T) - General Compute Optimized (C) - Compute bound applications that benefit from thigh performance processors Memory Optimized (R, X) - Optimized to deliver fast performance for workloads that process large data sets in memory (i.e. Elastic Cache) Accelerated Computing (P, G, Trn, Inf, DL, F, VT1) - Calculations, graphics processing or data pattern matching Storage Optimized (I, Dx, H1) - High, sequential read and write access to very large data sets on local storage. Low-latency, random I/O operations per second (IOPS) HPC Optimized (Hpc) - High Performance Computing - complex simulations and deep learning workloads Instance type naming conventions #More info: Amazon EC2 Instance type naming conventions\nExample #More info: Amazon EC2 Instance type naming conventions\nSeries Options - C ‚Äì Compute optimized\n- Hpc ‚Äì High performance computing\n- I ‚Äì Storage optimized\n- M ‚Äì General purpose\n- P ‚Äì GPU accelerated\n- R ‚Äì Memory optimized - a ‚Äì AMD processors\n- i ‚Äì Intel processors\n- b ‚Äì Block storage optimization\n- d ‚Äì Instance store volumes\n- e ‚Äì Extra storage (for storage optimized instance types), extra memory (for memory optimized instance types), or extra GPU memory (for accelerated computing instance types).\n- n ‚Äì Network and EBS optimized\n- q ‚Äì Qualcomm inference accelerators\n- z ‚Äì High CPU frequency Launching EC2 instance #EC2 \u0026gt; Launch Instance Name and Tags AMI Instance Type (t3.micro,t3.large,etc.) Key Pair Network Settings (Security Group) Storage Advanced Settings Domain Join IAM Instance Profile Hostname type Instance auto-recovery Shutdown behavior Termination protection Placement group Purchasing option None Capacity Blocks Spot Instances Capacity reservation User data Example user data #User data is only bootstrap script and only starts once during the machine creation.\n#!/bin/bash # Use this for your user data (script from top to bottom) # install httpd (Linux 2 version) yum update -y yum install -y httpd systemctl start httpd systemctl enable httpd echo \u0026#34;\u0026lt;h1\u0026gt;Hello World from $(hostname -f)\u0026lt;/h1\u0026gt;\u0026#34; \u0026gt; /var/www/html/index.html Connecting to EC2 from Windows Terminal #ssh -i .\\.ssh\\id_rsa_aws25 ec2-user@ec2-3-95-191-175.compute-1.amazonaws.com EC2 Instances Purchasing options # On-Demand instances - short workload, predictable pricing, pay by second Pay for what used Linux or Windows - billing per second after the first minute All other operating systems - billing per hour Highest cost but no upfront payment No long-term commitment Recommended for short-term and un-interrupted workloads Reserved (1 \u0026amp; 3 years) Up to 72% discount compared to On-demand You reserve a specific instance attributes (Instance Type, Region, Tenancy, OS) Reserved Instances - long workloads Payment options - No upfront, Partial Upfront, All Upfront Scope: Regional or Zonal Recommended for steady-state usage applications (think database) Can be bought and sold in the Reserved Instance Market place Convertible Reserved Instances - long workload with flexible instances Can change the EC2 instance type, instance family, OS, scope and tenancy Up to 66% discount Saving plans (1 \u0026amp; 3 years) - commitment to an amount of usage, long workloads Get discount based on long-term usage Commit to a certain type of usage ($10/hour for 1 or 3 years) Usage beyond EC2 Savings Plans is billed at the On-Demand price Locked to a specific instance family \u0026amp; AWS region Flexible across Instance Size (e.g. m5.xlarge, m5.2xlarge) OS (e.g. Linux, Windows) Tenancy (Host, Dedicated, Default) Spot Instances - short workloads, cheap, can lose instances Up to 90% discount Instances can be \u0026ldquo;lost\u0026rdquo; at any point if max price is less than current spot price Recommended for workloads that are resilient to failure Batch jobs Data analysis Image processing Dedicated Hosts - book an entire physical server, control instance placement A physical server with EC2 instance capacity fully dedicated to your use Recommended for for companies with strong compliance requirements OR server-bound software licenses (per-socket, per-core) Purchasing Options: On-demand Reserved Most expensive option Dedicated Instances - no other customers will share your hardware Instances run on a dedicated hardware May share hardware with other instances in the same account No control over instance placement Capacity Reservations - reserve capacity in a specific AZ for any duration Sources # EC2 Instance Types Amazon EC2 Instance type naming conventions EC2Instances.info Full YouTube Rahul\u0026rsquo;s AWS Course: https://www.youtube.com/playlist?list=PL7iMyoQPMtAN4xl6oWzafqJebfay7K8KP\nReferences # Security Groups Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"4 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/4-ec2/","section":"Posts","summary":"An Amazon EC2 instance is a virtual server in the AWS Cloud\u0026hellip;","title":"EC2"},{"content":"Setting up a budget #Billing and Cost Management is only available for the root user (or user with the right privileges).\n1. Enabling Billing and Cost Management for IAM user # Log in as root to AWS Console Click on your user in the top right corner, select an account Scroll down to \u0026ldquo;IAM user and role access to Billing information\u0026rdquo; Activate IAM access This will allow access to billing information for IAM users that are in Administrators group.\n2. Create a budget #Billing and Cost Management \u0026gt; Budgets \u0026gt; Create a budget Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"3 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/3-budget/","section":"Posts","summary":"AWS Budget\u0026hellip;","title":"Budget"},{"content":"IAM = Identity and Access management #IAM is AWS Global service.\nGroups only contain users, NOT other groups.\nUsers don\u0026rsquo;t have to belong to a group and user can belong to multiple groups.\nUsers or Groups can me assigned JSON documents called policies. Those policies define permissions for the users / groups.\nIn AWS you apply the least privilege principle: don\u0026rsquo;t give user more permission than they need.\nCreating user in AWS CLI #IAM console \u0026gt; Users Create user # Create group \u0026ldquo;admin\u0026rdquo; # IAM policies structure # IAM policies structure includes:\nVersion: policy version ID (Optional): identifier Statement: one or more statements (required) Statement consist of:\nSID: identifier (optional) Effect: Allow or Deny Principal: account / user / role to which policy is applied to Action: list of allowed or denied actions Resource: list of resources to which the action is applied to Condition: conditions for when the policy is applied (optional) MFA # Accessing AWS # AWS Management Console - protected by password + MFA AWS Command Line (CLI) - protected by access keys AWS Software Development Kit (SDK) - for code - protected by access keys Access Keys can be generated through AWS Console. Users manage their own access keys.\nAccess Key ID = username Secret Access Key = password\nCreating Access Key #IAM \u0026gt; Users \u0026gt; Username \u0026gt; Security Credentials \u0026gt; Access Keys \u0026gt; Create Access Key \u0026gt; Command Line Interface (CLI) Configuring AWS CLI with the new access key ## Configure AWS CLI aws configure # Test aws iam list-users IAM roles for Services # Some AWS services will need to perform actions on your behalf Those AWS services will need permissions to be assigned with IAM Roles Common Roles for Services:\nEC2 Instance Roles Lambda Function Roles Roles for CloudFormation Create AWS Service Role #IAM \u0026gt; Roles \u0026gt; Create role \u0026gt; AWS service Add permissions:\nIAM Security Tools # IAM Credentials Report (account-level) Report that lists all users and status of their credentials IAM \u0026gt; Credentials Report IAM Access Advisor (user-level) Access Advisor shows the service permissions granted to a user and when those services were last accessed IAM \u0026gt; Users \u0026gt; Username \u0026gt; Last Accessed IAM Access Advisor (Last Accessed) can be used to determine what user is accessing and to adjust his / her role in line with the \u0026ldquo;Least Privilege Principle\u0026rdquo;\nIAM Beset Practices # Don\u0026rsquo;t use root account One physical user = One AWS user Assign users to groups and assign permissions (policies) to groups Create strong password policy Use and enforce MFA Create and use Roles for giving permissions to AWS services Use Access Keys for Programmatic access (CLI / SDK) Audit permissions using IAM Credentials Report and IAM Access Advisor Never share IAM users \u0026amp; Access Keys Shared Responsibility Model for IAM # AWS Organization Infrastructure (global network security) Users, Groups, Roles, Policies management and monitoring Configuration and vulnerability analysis Enabling MFA on all accounts Compliance validation Rotating keys Using IAM tools to apply appropriate permissions Analyze access patterns and review permissions Sources # AWS Global Infrastructure: AWS Global Infrastructure Shared Responsibility Model: Shared Responsibility Model - Amazon Web Services (AWS) Full YouTube Rahul\u0026rsquo;s AWS Course: https://www.youtube.com/playlist?list=PL7iMyoQPMtAN4xl6oWzafqJebfay7K8KP\nReferences # Account Management and Billing Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"2 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/2-iam/","section":"Posts","summary":"Identity and Access management\u0026hellip;","title":"Identity and Access management"},{"content":" Private Cloud Public Cloud Hybrid Cloud Cloud services used by a single organization, not exposed to the public Cloud resources owned and operated by a third party cloud service provider delivered over the internet Keep some servers on premises and extend some capabilities to the cloud Complete control Security for sensitive applications Meet specific business needs Five characteristics of Cloud Computing # On-demand self service Users can provision resources and use them without human interaction from the service provider Broad network access Resources available over the network can be accessed by diverse client platforms Multi-tenancy and resource pooling Multiple customers can share the same infrastructure and applications with security and privacy Multiple customers are serviced from the same physical resources Rapid elasticity and scalability Automatically and quickly acquire and dispose resources when needed Quickly and easily scale based on demand Measured service Usage is measured, users pay for what they used Six advantages of Cloud Computing # Trade capital expense (CAPEX) for operational expense (OPEX) Pay On-Demand: don\u0026rsquo;t own the hardware Reduced Total Cost of Ownership (TCO) \u0026amp; Operational Expense (OPEX) Benefit from massive economies of scale Prices are reduced as AWS is more efficient due to a large scale Stop guessing the capacity Scale based on actual measured usage Increase speed and agility Stop spending money running and maintaining data centers Go global in minutes: leverage the AWS Global Infrastructure Problems solved by the cloud # Flexibility: change resources when needed Cost-Effectiveness: pay as you go and for what you use Scalability: accommodate larger loads by making hardware stronger or adding additional nodes Elasticity: ability to scale out and scale in when needed High-Availability and Fault-Tolerance: build across data centers Agility: rapidly develop, test and launch software applications Types of Cloud Computing # Infrastructure as a Service (IaaS) Provides building blocks for cloud IT Provides networking, compute, storage Highest level of flexibility Easy parallel with traditional on-premises IT Platform as a Service (PaaS) Removes the need for your organization to manage the underlying infrastcucture Focus on the deployment and management of your applications Software as a Service (SaaS) Completed product that is run and managed by the service provider AWS Global Infrastructure # AWS Regions AWS Availability Zones AWS Data Centers AWS Edge Locations / Points of Presence AWS Global Infrastructure: AWS Global Infrastructure\nShared Responsibility Model # Shared Responsibility Model: Shared Responsibility Model - Amazon Web Services (AWS)\nSources # AWS Global Infrastructure: AWS Global Infrastructure Shared Responsibility Model: Shared Responsibility Model - Amazon Web Services (AWS) Disclaimer # Disclaimer: Content for educational purposes only, no rights reserved.\nMost of the content in this series is coming from Stephane Maarek\u0026rsquo;s Ultimate AWS Certified Cloud Practitioner CLF-C02 2025 course on Udemy.\nI highly encourage you to take the Stephane\u0026rsquo;s courses as they are awesome and really help understanding the subject.\nMore about Stephane Maarek:\nhttps://www.linkedin.com/in/stephanemaarek https://x.com/stephanemaarek This article is just a summary and has been published to help me learning and passing the practitioner exam.\n","date":"1 August 2025","permalink":"https://rtdevx.github.io/posts/training/aws/2025-aws-cloud-practitioner/1-what-is-cloud-computing/","section":"Posts","summary":"What is Cloud Computing\u0026hellip;","title":"What is Cloud Computing"},{"content":"What is Game Theory? #Game Theory, branch of applied mathematics that provides tools for analyzing situations in which parties, called players, make decisions that are interdependent.\nThis interdependence causes each player to consider the other player‚Äôs possible decisions, or strategies, in formulating strategy. A solution to a game describes the optimal decisions of the players, who may have similar, opposed, or mixed interests, and the outcomes that may result from these decisions.\nSource: https://www.britannica.com/science/game-theory\nWhere the Game Theory is applied #Despite of the above definition, Game Theory is present everywhere around us in our daily life. For that reason it is important to be at least briefly familiar with the concept.\nSo much of the theory\u0026hellip; This is literally mind blowing video that really is worth watching\u0026hellip;\nEnjoy üôè\nThis game theory problem will change the way you see the world\n","date":"22 July 2025","permalink":"https://rtdevx.github.io/posts/productivity/2025/250822-game-theory/","section":"Posts","summary":"The best video about Game Theory I\u0026rsquo;ve ever watched\u0026hellip;","title":"Game theory"},{"content":"","date":null,"permalink":"https://rtdevx.github.io/categories/productivity/","section":"Categories","summary":"","title":"Productivity"},{"content":"","date":null,"permalink":"https://rtdevx.github.io/tags/zettelkasten/","section":"Tags","summary":"","title":"Zettelkasten"},{"content":"What is the Zettelkasten method? #Zettelkasten is a system of identifiers to link the notes and navigating between them. This methodology leads to higher productivity.\nZettelkasten is not only a note taking system. It is a tool that is used for thinking since it brings a structure to note taking and \u0026ldquo;connecting the dots\u0026rdquo;.\nThis method is often called a \u0026ldquo;second brain\u0026rdquo;. And it is so for a reason\u0026hellip;\nThe history of the Zettelkasten method #The Zettelkasten method was created in the 20th century by social scientist Niklas Luhman. He used this system to organize his thoughts and research, which allowed him to publish more than 50 books and hundreds of articles. Luhman used physical slip boxes for his Zettelkasten, adding notes and sub notes into the box as he created new ideas.\nWriting is understanding! #Each note contains the thought or idea and should be written in own words. This helps mapping the ideas in human brain. Process similar to translation takes place which helps with understanding the topic.\nStructuring, simplifying and linking ideas helping storing them outside of the brain and helping with solving complex problems.\nA good system removes the need for remembering everything.\nI only do what is easy. I only write when I immediately know how to do it. If I falter for a moment, I put the matter aside and do something else.\nNiklas Luhmann\nHighly productive people deflect resistance like judo champions. Having a flexible workflow allows doing this. This is known as \u0026ldquo;effortless productivity\u0026rdquo;.\nContent Consumption # Intentionality for content consumption 80% of content consumed scheduled and aligned with goals articles reading, YouTube videos watching are all scheduled beforehand with a clear purpose each act of content consumption should align with one of the goals set 20% of content consumption used for relaxing Intentionality # Consume the content with an intention of writing increased focus allows adapting more observant and analytical perspective Being intentional about content consumption will limit the content consumption Obsidian - markdown-based, multi-platform note taking app #Obsidian is a note-taking app that lets you link notes together. Learn how to download, create, and organize your notes with Obsidian in this comprehensive guide.\nwww: https://obsidian.md/\nZettelkasten Smart Notes: Step by Step with Obsidian\nNote Taking # Clear thinking becomes clear writing. One cannot exist without the other\nWilliam Zinnser\nFleeting notes #Notes being taken during content consumption are called Fleeting Notes. These are being used only as a reminder to take action later and put notes in the right order.\nEphemeral - temporary, should be processed on the same or next day Brief - few words or ideas Quick capture This ability is a cornerstone of effective learning and productivity.\nPermanent notes # Articulated\nWritten in own words\nSolidified\nOne idea per card\nDo not copy\nBrief and concise\nWrite to publish\nQuotes allowed - they add context and can add value\nConsistency in transferring Fleeting notes to Permanent notes should be frequent / daily.\nLinking notes # Linking permanent notes is a powerful way of building knowledge Allows to see connection between notes Makes easier to recall and apply knowledge Don\u0026rsquo;t collect information. Gather knowledge instead. Linking leads to surprises\u0026hellip;\nTags vs Folders #Folders are for separating, tags are for uniting\nAvoid moving files around Navigation benefits Satisfaction of collecting in folders Note taking system should free up time Sources #Zettelkasten # Introduction to the Zettelkasten Method How to Use the Zettelkasten Method for Notetaking Obsidian # Obsidian - Sharpen your thinking ","date":"19 July 2025","permalink":"https://rtdevx.github.io/posts/productivity/2025/250819-zettelkasten/","section":"Posts","summary":"Increase your productivity with zettelkasten, highly effective note taking method\u0026hellip;","title":"Zettelkasten note taking method"},{"content":" 1. Pomodoro ritual #25 minutes focus, 5 minutes break.\nClose your eyes, take a breath and make a focus statement (what to accomplish in those 25 minutes). Declare out loud OR write down. filters distractions sharpens attention mentally commits completion 2. The Kanji Recall method #Kanji = visual memory / mental map.\nGrid Recall (repetition) Visualizing Drawing along with saying / reading / writing words 3. Rewrite notes #Rewriting notes stimulates active recall.\nThe basic definition Reworded version Diagram Story or metaphor In their own words like teaching a friend 4. Empty cup mindset #This method originates from Zen Buddhism.\nYou can\u0026rsquo;t pour tea into a cup. Idea of dropping ego while learning and discover what student doesn\u0026rsquo;t know yet.\nApproach learning with humility and curiosity, not pressure and ego (i.e. grades, etc\u0026hellip;). Value is not in your score but in your growth.\n5. Chain learning #Study like everything is connected. Because in real world \u0026hellip;it is.\n6. Study like a Sensei that is teaching others #Mastery is shown in clarity, when you can explain the subject. When you teach something, you truly learn it. Explain it like you were explaining it to a 10 year old.\nThis approach was first avowed by Richard Feynman, a Nobel winning physicist.\nIf you can\u0026rsquo;t explain it simply, you don\u0026rsquo;t understand it well enough.\nRichard Feynman\n*although according to many sources this quote is attributed to Albert Einstein\n7. The forbidden night school #From 7pm to 9pm - no phones, no distractions, no background noise. Collaborate on reviewing, revising if and where possible. Mostly for students.\n","date":"17 July 2025","permalink":"https://rtdevx.github.io/posts/productivity/2025/250717-7-studying-techniques/","section":"Posts","summary":"Pomodoro, Kanji, Rewrite notes, Empty cup mindset, Chain learning, Study like a sensei, The forbidden night school\u0026hellip;","title":"7 Chinese and Japanese studying techniques"}]